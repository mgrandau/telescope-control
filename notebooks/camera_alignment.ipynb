{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Alignment\n",
    "\n",
    "This notebook aligns the 2 cameras on the telescope (Finder Camera and main OTA camera). Information on the finder camera can be found at _/telescope-control/finder-camera/finder-camera-information.md_\n",
    "\n",
    "## Questions:\n",
    "\n",
    "### Can the All Sky camera be used to put a start in the telescopes OTA field of view?\n",
    "\n",
    "* The ASI482MC's theoretical FOV is 23.91 x 13.45 arcmin (see _astrophotography_camera_exposure_times.ipynb_)\n",
    "* The ASI120MC-S 150 All Sky's theoretical FOV per pixel is 422 arcseconds or approximately 7 arcmin (see _astrophotography_camera_exposure_times.ipynb_)\n",
    "\n",
    "Based on the above information it should be possible to get whatever a singe pixel points at in the camera.\n",
    "\n",
    "### What is the best exposure for the finder camera?\n",
    "\n",
    "* The ASI120MC-S's All sky max exposure is 176 seconds before images start to blur (see _astrophotography_camera_exposure_times.ipynb_)\n",
    "* User needs feedback something is happening if it takes over a second. \n",
    "* Longer the exposure time the more we can draw light from the sky.\n",
    "* The finder cameras exposure time is independent of the use off tracking.\n",
    "\n",
    "On movement ramp the exposure time up. This would make stars to appear dimmer but to become sharper and exceed normal human sight. This way you get feedback the telescope is moving based on the movement of terrestrial things in the view. But once the motion stops the stars become more pronounced. This is similar to the painters algorithm in CAD. Things closer are drawn first.\n",
    "\n",
    "### What is the best gain for the finder camera?\n",
    "\n",
    "* The primary point of gain is to expose the terrestrial objects at night as a reference point. So we want to set the gain based on the fastest exposure.\n",
    "* The gain should auto adjust based on the darkness of the night. This will allow for twilight viewing and for the strength of the moon if present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Notebook\n",
    "\n",
    "Make sure everything is up to date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/mark/.local/lib/python3.10/site-packages (22.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/mark/.local/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mark/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/lib/python3/dist-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /home/mark/.local/lib/python3.10/site-packages (8.0.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/mark/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/mark/.local/lib/python3.10/site-packages (from ipywidgets) (6.15.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/mark/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/mark/.local/lib/python3.10/site-packages (from ipywidgets) (8.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/mark/.local/lib/python3.10/site-packages (from ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: packaging in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.2.1)\n",
      "Requirement already satisfied: psutil in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.5)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/mark/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: stack-data in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (59.6.0)\n",
      "Requirement already satisfied: decorator in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/mark/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.30)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/mark/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /home/mark/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mark/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/mark/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: wcwidth in /home/mark/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (2.4.7)\n",
      "Requirement already satisfied: asttokens in /home/mark/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.8)\n",
      "Requirement already satisfied: executing in /home/mark/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/mark/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!python3 -m pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from workflow_logger import WorkflowLogger\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import asi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terrestrial Daylight Alignment\n",
    "\n",
    "The idea is that I can use a daylight distant object like a power line connection to align the 2 cameras. We will want the zoom level to be high enough to ensure we can get the exact pixel position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "workflow_log : pd.DataFrame = WorkflowLogger().get_workflow_log()\n",
    "\n",
    "# List the connected camera's\n",
    "cameras = asi.getConnectedCameras()\n",
    "print(\"Connected camera's:\")\n",
    "\n",
    "for camera_number in cameras:\n",
    "    print(cameras[camera_number]['Name'])\n",
    "\n",
    "print(dir(asi))\n",
    "print(dir(asi.Camera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import asi\n",
    "import cv2\n",
    "from typing import Optional\n",
    "\n",
    "class AlignmentFinderCamera(object):\n",
    "    _video = None\n",
    "    _exposure = 2000000\n",
    "    _offset_cross = (-12,-8)\n",
    "    _gain = 0\n",
    "    last_image: Optional[bytes] = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self._video = asi.Camera(0)\n",
    "        self._video.setCaptureFrameFormat(1280, 960, 1, \"RGB24\")\n",
    "        self._video.setControlValueManual(\"ASI_GAIN\", self._gain)\n",
    "        self._video.setControlValueManual(\"ASI_WB_R\", 55)\n",
    "        self._video.setControlValueManual(\"ASI_WB_B\", 77)\n",
    "\n",
    "    def __del__(self):\n",
    "        del self._video\n",
    "\n",
    "    def get_frame(self) -> bytes:\n",
    "        self.last_image, bin, success = self._video.grab(self._exposure)\n",
    "        b,g,r = cv2.split(self.last_image)\n",
    "        corrected_image = cv2.merge ( (r, g, b) )\n",
    "        #print(self.last_image.shape)\n",
    "        png = corrected_image[80-self._offset_cross[0]:880-self._offset_cross[0],240-self._offset_cross[1]:1040-self._offset_cross[1]]\n",
    "        #print(png.shape)\n",
    "        #ret, png = cv2.imencode('.png', self.last_image)\n",
    "\n",
    "        cross = cv2.imread('overlays/alignment-cross-hair.png')\n",
    "        #print(cross.shape)\n",
    "        #overlay = cv2.imencode('.png',cv2.imread('cross-hair.png'))\n",
    "        added_image = cv2.addWeighted(png,1,cross,1,0,dtype = cv2.CV_32F)\n",
    "        \n",
    "        ret, jpeg = cv2.imencode('.jpg', added_image)\n",
    "        return jpeg.tobytes()\n",
    "\n",
    "class AlignmentOtaCamera(object):\n",
    "    _video = None\n",
    "    _exposure = 2000000\n",
    "    _offset_cross = (0,0)\n",
    "    _gain = 0\n",
    "    last_image: Optional[bytes] = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self._video = asi.Camera(0)\n",
    "        self._video.setCaptureFrameFormat(1920, 1080, 1, \"RGB24\")\n",
    "        self._video.setControlValueManual(\"ASI_GAIN\", self._gain)\n",
    "        self._video.setControlValueManual(\"ASI_WB_R\", 55)\n",
    "        self._video.setControlValueManual(\"ASI_WB_B\", 77)\n",
    "\n",
    "    def __del__(self):\n",
    "        del self._video\n",
    "\n",
    "    def get_frame(self) -> bytes:\n",
    "        self.last_image, bin, success = self._video.grab(self._exposure)\n",
    "        b,g,r = cv2.split(self.last_image)\n",
    "        corrected_image = cv2.merge ( (r, g, b) )\n",
    "        #print(self.last_image.shape)\n",
    "        png = corrected_image[80-self._offset_cross[0]:880-self._offset_cross[0],240-self._offset_cross[1]:1040-self._offset_cross[1]]\n",
    "        #print(png.shape)\n",
    "        #ret, png = cv2.imencode('.png', self.last_image)\n",
    "\n",
    "        cross = cv2.imread('overlays/alignment-cross-hair.png')\n",
    "        #print(cross.shape)\n",
    "        #overlay = cv2.imencode('.png',cv2.imread('cross-hair.png'))\n",
    "        added_image = cv2.addWeighted(png,1,cross,1,0,dtype = cv2.CV_32F)\n",
    "        \n",
    "        ret, jpeg = cv2.imencode('.jpg', added_image)\n",
    "        return jpeg.tobytes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse\n",
    "import threading\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def run():\n",
    "    uvicorn.run(app)\n",
    "      \n",
    "def start_api():\n",
    "    _api_thread = threading.Thread(target=run)\n",
    "    _api_thread.start()\n",
    "    \n",
    "def create_alignment_finder_stream(): \n",
    "    alignment_finder_camera: AlignmentFinderCamera  = AlignmentFinderCamera()    \n",
    "    while True:\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(alignment_finder_camera.get_frame()) + b'\\r\\n\\r\\n')\n",
    "\n",
    "def create_alignment_ota_stream(): \n",
    "    alignment_ota_camera: AlignmentOtaCamera  = AlignmentOtaCamera()    \n",
    "    while True:\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(alignment_ota_camera.get_frame()) + b'\\r\\n\\r\\n')\n",
    "      \n",
    "@app.get(\"/finder\")\n",
    "def get_alignment_finder_video_stream():\n",
    "    return StreamingResponse(create_alignment_finder_stream(), media_type='multipart/x-mixed-replace; boundary=frame')\n",
    "    \n",
    "@app.get(\"/ota\")\n",
    "def create_alignment_ota_stream():\n",
    "    return StreamingResponse(create_alignment_finder_stream(), media_type='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "start_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set the finder camera for daylight viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML \n",
    "<img src=\"http://127.0.0.1:8000/finder\" width=640 />\n",
    "\n",
    "WorkflowLogger('Step 1: Set the finder camera for daylight viewing', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set the OTA camera for daylight viewing. Display a cross-hair object in the center of the OTA camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML \n",
    "<img src=\"http://127.0.0.1:8000/ota\" width=640 />\n",
    "\n",
    "WorkflowLogger('Step 2: Set the OTA camera for daylight viewing', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Point the telescopes OTA at any easy to identify object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Set the cross-hair on the finder camera to correspond with object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Point the finder scope at a different object, record the offset difference in the OTA (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Point the finder scope at a different object, record the offset difference in the OTA (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Point the finder scope at a different object, record the offset difference in the OTA (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Point the finder scope at a different object, record the offset difference in the OTA (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Point the finder scope at a different object, record the offset difference in the OTA (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Save alignment data and workflow results to the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e949c581f3754843be7578d11ed5bb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Comments:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aca059ee9949e5b6cc5c2ada531192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Done', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af43bc01d4541f6a5dfb7f2df85067f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WorkflowLogger('Step 1', workflow_log).display()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
